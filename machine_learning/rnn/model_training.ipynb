{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rishi-latchmepersad/TinyML-Home-Weather-Forecasting/blob/main/machine_learning/rnn/model_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4a67821c"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/rishi-latchmepersad/TinyML-Home-Weather-Forecasting/blob/main/machine_learning/rnn/model_training.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_cMTmtr-SYL"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import requests\n",
        "from datetime import datetime\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rA7oWexqkqI"
      },
      "source": [
        "# Import Data\n",
        "We need to concatenate all readings from the on-device measurement CSVs and augment the dataset with a year of Open-Meteo historical data for Calcutta #3, Couva, Trinidad (August 2024 through August 2025)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80e471ff"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Locate measurement CSVs whether running locally or in Colab\n",
        "candidate_dirs = [\n",
        "    Path('/content/measurements'),\n",
        "    Path('measurements'),\n",
        "    Path('../measurements'),\n",
        "]\n",
        "measurements_dir = None\n",
        "for candidate in candidate_dirs:\n",
        "    if candidate.exists():\n",
        "        measurements_dir = candidate\n",
        "        break\n",
        "if measurements_dir is None:\n",
        "    raise FileNotFoundError(\"Could not find a measurements directory in the expected locations.\")\n",
        "\n",
        "csv_files = sorted(measurements_dir.glob('measurements_*.csv'))\n",
        "if not csv_files:\n",
        "    raise FileNotFoundError(f\"No measurement CSVs found under {measurements_dir}\")\n",
        "\n",
        "measurement_dfs = []\n",
        "for csv_file in csv_files:\n",
        "    df_temp = pd.read_csv(csv_file)\n",
        "    measurement_dfs.append(df_temp)\n",
        "\n",
        "measurement_df = pd.concat(measurement_dfs, ignore_index=True)\n",
        "print(f\"Successfully loaded and concatenated {len(csv_files)} CSV files into a single DataFrame.\")\n",
        "print(f\"The final measurement DataFrame has {measurement_df.shape[0]} rows and {measurement_df.shape[1]} columns.\")\n",
        "measurement_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1484aa5f"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Keep only the columns needed for the long-to-wide pivot and coerce values to numeric\n",
        "measurement_df = measurement_df[[\"timestamp_iso8601\", \"quantity\", \"value\"]]\n",
        "measurement_df[\"value\"] = pd.to_numeric(measurement_df[\"value\"], errors=\"coerce\")\n",
        "measurement_df = measurement_df.dropna(subset=[\"timestamp_iso8601\", \"quantity\", \"value\"])\n",
        "measurement_df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44a4aa90"
      },
      "source": [
        "## Pull one year of Open-Meteo data for Calcutta #3 (Couva, Trinidad)\n",
        "We fetch August 2024 through August 2025 hourly history so the model can train on both on-device measurements and public weather data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43912ab0"
      },
      "outputs": [],
      "source": [
        "\n",
        "openmeteo_params = {\n",
        "    \"latitude\": 10.4226,  # Calcutta #3, Couva, Trinidad\n",
        "    \"longitude\": -61.4749,\n",
        "    \"start_date\": \"2024-08-01\",\n",
        "    \"end_date\": \"2025-08-01\",\n",
        "    \"hourly\": [\n",
        "        \"temperature_2m\",\n",
        "        \"relative_humidity_2m\",\n",
        "        \"surface_pressure\",\n",
        "        \"precipitation\",\n",
        "        \"wind_speed_10m\",\n",
        "    ],\n",
        "    \"timezone\": \"UTC\",\n",
        "}\n",
        "\n",
        "response = requests.get(\n",
        "    \"https://archive-api.open-meteo.com/v1/archive\",\n",
        "    params={**openmeteo_params, \"hourly\": \",\".join(openmeteo_params[\"hourly\"])},\n",
        "    timeout=60,\n",
        ")\n",
        "response.raise_for_status()\n",
        "openmeteo_hourly = response.json()[\"hourly\"]\n",
        "\n",
        "openmeteo_long_records = []\n",
        "quantity_rename = {\n",
        "    \"temperature_2m\": \"om_temperature_2m_c\",\n",
        "    \"relative_humidity_2m\": \"om_relative_humidity_pct\",\n",
        "    \"surface_pressure\": \"om_surface_pressure_pa\",\n",
        "    \"precipitation\": \"om_precipitation_mm\",\n",
        "    \"wind_speed_10m\": \"om_wind_speed_10m_ms\",\n",
        "}\n",
        "for param_key, column_name in quantity_rename.items():\n",
        "    values = openmeteo_hourly[param_key]\n",
        "    if param_key == \"surface_pressure\":\n",
        "        values = [v * 100 for v in values]\n",
        "    for ts, value in zip(openmeteo_hourly[\"time\"], values):\n",
        "        openmeteo_long_records.append(\n",
        "            {\"timestamp_iso8601\": ts, \"quantity\": column_name, \"value\": value}\n",
        "        )\n",
        "\n",
        "openmeteo_df = pd.DataFrame(openmeteo_long_records)\n",
        "openmeteo_df[\"timestamp_iso8601\"] = pd.to_datetime(\n",
        "    openmeteo_df[\"timestamp_iso8601\"], utc=True\n",
        ")\n",
        "print(\n",
        "    f\"Loaded {len(openmeteo_df)} Open-Meteo rows spanning \"\n",
        "    f\"{openmeteo_df['timestamp_iso8601'].min()} to {openmeteo_df['timestamp_iso8601'].max()}.\"\n",
        ")\n",
        "openmeteo_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9f6f4b0"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Combine the device measurements with the Open-Meteo history\n",
        "combined_df = pd.concat([measurement_df, openmeteo_df], ignore_index=True)\n",
        "df = combined_df\n",
        "df[\"timestamp_iso8601\"] = pd.to_datetime(df[\"timestamp_iso8601\"], format='mixed', utc=True)\n",
        "print(f\"Combined dataset has {len(df)} rows from {df['timestamp_iso8601'].min()} to {df['timestamp_iso8601'].max()}\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WYpaIjX-1dy"
      },
      "source": [
        "# Data Pre-Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJtrIkgbrE9k"
      },
      "source": [
        "## Pivoting - Reformating the data into multiple columns\n",
        "We make each quantity (measurement type e.g. lux, pressure, temperature) its own column, so each row will have one value per quantity instead of one row per quantity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7U3BR4_Cc8FE"
      },
      "outputs": [],
      "source": [
        "df[\"quantity\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrxuOZIDdLqM"
      },
      "outputs": [],
      "source": [
        "df = df.pivot_table(values='value', index='timestamp_iso8601',\n",
        "                       columns='quantity', aggfunc=\"mean\").reset_index()\n",
        "print(df.columns.name)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gjavwOGGC9rF"
      },
      "outputs": [],
      "source": [
        "df.columns.name = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R1Rpy3yzB7Jm"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Drop rain indicator if present (older datasets sometimes include it)\n",
        "if \"is_raining\" in df.columns:\n",
        "    df = df.drop([\"is_raining\"], axis=1)\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjAo2AvWfKse"
      },
      "outputs": [],
      "source": [
        "len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-tlJ5x1hO7Y"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_pSPh7CiWVE"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmHwIzHyr-Bc"
      },
      "source": [
        "## Resampling - Handling small gaps between sensor readings\n",
        "Each quantity is captured by a different sensor. Since the data is captured every 10 seconds, there may be very slight differences (seconds or milliseconds) between when each sensor actually captures its information. This results in readings that represent the same 10 second period appear as different rows. In reality, they should represent the same instance. **Resampling** organizes the data into 30 minute chunks, and takes the average of each value within that 30 minute chunk, thus consolidating them into a single row."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQKNXOXJiZ_j"
      },
      "outputs": [],
      "source": [
        "df[\"timestamp_iso8601\"] = pd.to_datetime(df[\"timestamp_iso8601\"], format='mixed')\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wyj54dEvjDR_"
      },
      "outputs": [],
      "source": [
        "# In the original dataset, the sensor readings may have come in at very slightly\n",
        "# different times, i.e. 1 second apart. But each of these should have technically\n",
        "# been one instance. So we resample, to get the average of each value within the\n",
        "# specified resample time.\n",
        "\n",
        "df = df.set_index(\"timestamp_iso8601\").resample('30min').mean()\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "drjCedVNjTLA"
      },
      "outputs": [],
      "source": [
        "len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AaSFT8SVf9OP"
      },
      "outputs": [],
      "source": [
        "df = df.sort_values(\"timestamp_iso8601\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HbvScXOtvHV"
      },
      "source": [
        "## Interpolation - Handling gaps in the continuous time data\n",
        "After resampling, there would have been periods where the board was turned off. This results in gaps in the data. Interpolation uses the nearest values to the missing times to fill them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "id": "NsBr57b3FN88",
        "outputId": "92d9208e-5bba-451f-9999-6df0713d3a8b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                           humidity_pct    lux_lx  om_precipitation_mm  \\\n",
              "timestamp_iso8601                                                        \n",
              "2025-09-04 22:00:00+00:00     -1.849565 -0.655435                  0.0   \n",
              "2025-09-04 22:30:00+00:00     -1.312136 -0.653129                  0.0   \n",
              "2025-09-04 23:00:00+00:00     -0.868645 -0.644958                  0.0   \n",
              "2025-09-04 23:30:00+00:00     -0.747509 -0.644901                  0.0   \n",
              "2025-09-05 00:00:00+00:00     -0.552051 -0.644897                  0.0   \n",
              "\n",
              "                           om_relative_humidity_pct  om_surface_pressure_pa  \\\n",
              "timestamp_iso8601                                                             \n",
              "2025-09-04 22:00:00+00:00                       0.0                     0.0   \n",
              "2025-09-04 22:30:00+00:00                       0.0                     0.0   \n",
              "2025-09-04 23:00:00+00:00                       0.0                     0.0   \n",
              "2025-09-04 23:30:00+00:00                       0.0                     0.0   \n",
              "2025-09-05 00:00:00+00:00                       0.0                     0.0   \n",
              "\n",
              "                           om_temperature_2m_c  om_wind_speed_10m_ms  \\\n",
              "timestamp_iso8601                                                      \n",
              "2025-09-04 22:00:00+00:00         7.105427e-15         -3.552714e-15   \n",
              "2025-09-04 22:30:00+00:00         7.105427e-15         -3.552714e-15   \n",
              "2025-09-04 23:00:00+00:00         7.105427e-15         -3.552714e-15   \n",
              "2025-09-04 23:30:00+00:00         7.105427e-15         -3.552714e-15   \n",
              "2025-09-05 00:00:00+00:00         7.105427e-15         -3.552714e-15   \n",
              "\n",
              "                           pressure_pa  temperature_c  sine_hour  cos_hour  \\\n",
              "timestamp_iso8601                                                            \n",
              "2025-09-04 22:00:00+00:00    -0.534381      -0.173247  -0.709987  1.225918   \n",
              "2025-09-04 22:30:00+00:00    -0.558529      -0.130578  -0.709987  1.225918   \n",
              "2025-09-04 23:00:00+00:00    -0.534775       0.414303  -0.368763  1.367140   \n",
              "2025-09-04 23:30:00+00:00    -0.325886       0.350705  -0.368763  1.367140   \n",
              "2025-09-05 00:00:00+00:00    -0.219706       0.207997  -0.002585  1.415308   \n",
              "\n",
              "                           delta_temperature  temp_mean_6h  humidity_mean_6h  \\\n",
              "timestamp_iso8601                                                              \n",
              "2025-09-04 22:00:00+00:00           0.000000     -0.205588         -1.910267   \n",
              "2025-09-04 22:30:00+00:00           0.173283     -0.180186         -1.631824   \n",
              "2025-09-04 23:00:00+00:00           2.224210      0.044540         -1.385826   \n",
              "2025-09-04 23:30:00+00:00          -0.260682      0.137972         -1.231447   \n",
              "2025-09-05 00:00:00+00:00          -0.583754      0.160048         -1.098313   \n",
              "\n",
              "                           target_temperature_c  \n",
              "timestamp_iso8601                                \n",
              "2025-09-04 22:00:00+00:00             28.172483  \n",
              "2025-09-04 22:30:00+00:00             28.347315  \n",
              "2025-09-04 23:00:00+00:00             30.579943  \n",
              "2025-09-04 23:30:00+00:00             30.319356  \n",
              "2025-09-05 00:00:00+00:00             29.734615  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-09b76748-990f-4fc5-b112-cf7bedbfe620\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>humidity_pct</th>\n",
              "      <th>lux_lx</th>\n",
              "      <th>om_precipitation_mm</th>\n",
              "      <th>om_relative_humidity_pct</th>\n",
              "      <th>om_surface_pressure_pa</th>\n",
              "      <th>om_temperature_2m_c</th>\n",
              "      <th>om_wind_speed_10m_ms</th>\n",
              "      <th>pressure_pa</th>\n",
              "      <th>temperature_c</th>\n",
              "      <th>sine_hour</th>\n",
              "      <th>cos_hour</th>\n",
              "      <th>delta_temperature</th>\n",
              "      <th>temp_mean_6h</th>\n",
              "      <th>humidity_mean_6h</th>\n",
              "      <th>target_temperature_c</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>timestamp_iso8601</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2025-09-04 22:00:00+00:00</th>\n",
              "      <td>-1.849565</td>\n",
              "      <td>-0.655435</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.105427e-15</td>\n",
              "      <td>-3.552714e-15</td>\n",
              "      <td>-0.534381</td>\n",
              "      <td>-0.173247</td>\n",
              "      <td>-0.709987</td>\n",
              "      <td>1.225918</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.205588</td>\n",
              "      <td>-1.910267</td>\n",
              "      <td>28.172483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-09-04 22:30:00+00:00</th>\n",
              "      <td>-1.312136</td>\n",
              "      <td>-0.653129</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.105427e-15</td>\n",
              "      <td>-3.552714e-15</td>\n",
              "      <td>-0.558529</td>\n",
              "      <td>-0.130578</td>\n",
              "      <td>-0.709987</td>\n",
              "      <td>1.225918</td>\n",
              "      <td>0.173283</td>\n",
              "      <td>-0.180186</td>\n",
              "      <td>-1.631824</td>\n",
              "      <td>28.347315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-09-04 23:00:00+00:00</th>\n",
              "      <td>-0.868645</td>\n",
              "      <td>-0.644958</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.105427e-15</td>\n",
              "      <td>-3.552714e-15</td>\n",
              "      <td>-0.534775</td>\n",
              "      <td>0.414303</td>\n",
              "      <td>-0.368763</td>\n",
              "      <td>1.367140</td>\n",
              "      <td>2.224210</td>\n",
              "      <td>0.044540</td>\n",
              "      <td>-1.385826</td>\n",
              "      <td>30.579943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-09-04 23:30:00+00:00</th>\n",
              "      <td>-0.747509</td>\n",
              "      <td>-0.644901</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.105427e-15</td>\n",
              "      <td>-3.552714e-15</td>\n",
              "      <td>-0.325886</td>\n",
              "      <td>0.350705</td>\n",
              "      <td>-0.368763</td>\n",
              "      <td>1.367140</td>\n",
              "      <td>-0.260682</td>\n",
              "      <td>0.137972</td>\n",
              "      <td>-1.231447</td>\n",
              "      <td>30.319356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-09-05 00:00:00+00:00</th>\n",
              "      <td>-0.552051</td>\n",
              "      <td>-0.644897</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.105427e-15</td>\n",
              "      <td>-3.552714e-15</td>\n",
              "      <td>-0.219706</td>\n",
              "      <td>0.207997</td>\n",
              "      <td>-0.002585</td>\n",
              "      <td>1.415308</td>\n",
              "      <td>-0.583754</td>\n",
              "      <td>0.160048</td>\n",
              "      <td>-1.098313</td>\n",
              "      <td>29.734615</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-09b76748-990f-4fc5-b112-cf7bedbfe620')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-09b76748-990f-4fc5-b112-cf7bedbfe620 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-09b76748-990f-4fc5-b112-cf7bedbfe620');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-431fb5b3-ac36-4002-8300-d7a4070a4fe7\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-431fb5b3-ac36-4002-8300-d7a4070a4fe7')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-431fb5b3-ac36-4002-8300-d7a4070a4fe7 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"timestamp_iso8601\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2025-09-04 22:00:00+00:00\",\n        \"max\": \"2025-09-05 00:00:00+00:00\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2025-09-04 22:30:00+00:00\",\n          \"2025-09-05 00:00:00+00:00\",\n          \"2025-09-04 23:00:00+00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"humidity_pct\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5193953633618473,\n        \"min\": -1.849564960587837,\n        \"max\": -0.5520514605456489,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -1.312136340138704,\n          -0.5520514605456489,\n          -0.8686446242152054\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lux_lx\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.005193024196893225,\n        \"min\": -0.6554352062980944,\n        \"max\": -0.64489727562503,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -0.6531291668734269,\n          -0.64489727562503,\n          -0.6449575237026594\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"om_precipitation_mm\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"om_relative_humidity_pct\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"om_surface_pressure_pa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"om_temperature_2m_c\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 7.105427357601002e-15,\n        \"max\": 7.105427357601002e-15,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          7.105427357601002e-15\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"om_wind_speed_10m_ms\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": -3.552713678800501e-15,\n        \"max\": -3.552713678800501e-15,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          -3.552713678800501e-15\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pressure_pa\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1527643939027867,\n        \"min\": -0.558528596764147,\n        \"max\": -0.21970580166628334,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -0.558528596764147\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"temperature_c\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.27175756141170815,\n        \"min\": -0.1732468230920015,\n        \"max\": 0.4143027449576215,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -0.1305783999822205\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sine_hour\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.29451187220447955,\n        \"min\": -0.7099870189590678,\n        \"max\": -0.0025846053045050594,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          -0.7099870189590678\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cos_hour\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08836082724257165,\n        \"min\": 1.2259179360719228,\n        \"max\": 1.4153084101722917,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1.2259179360719228\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"delta_temperature\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.107188107984815,\n        \"min\": -0.5837539157037709,\n        \"max\": 2.2242095039780683,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.17328335935645556\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"temp_mean_6h\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.17392186840861798,\n        \"min\": -0.20558796668465107,\n        \"max\": 0.16004764317796802,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -0.18018587460066493\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"humidity_mean_6h\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3242151921080822,\n        \"min\": -1.910267498231528,\n        \"max\": -1.098312654626166,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -1.6318238974653794\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target_temperature_c\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1135154232496212,\n        \"min\": 28.172483136842104,\n        \"max\": 30.579943310344827,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          28.347315244444445\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "df.loc[\"2025-09-04 22:00:00+00:00\":\"2025-09-05 00:00:00+00:00\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgoQ0nnnopWC",
        "outputId": "e993c068-8575-4da1-b9ed-ecba65d95663"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data ranges from 2025-09-04 22:00:00+00:00 to 2025-10-21 19:00:00+00:00 and we have 2251 instances\n"
          ]
        }
      ],
      "source": [
        "print(f\"Data ranges from {df.index[0]} to {df.index[-1]} and we have {len(df)} instances\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4219Ry4I3A6",
        "outputId": "4f02020d-2f47-4758-fa7a-a404a5da7427"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 2251 entries, 2025-09-04 22:00:00+00:00 to 2025-10-21 19:00:00+00:00\n",
            "Freq: 30min\n",
            "Data columns (total 15 columns):\n",
            " #   Column                    Non-Null Count  Dtype  \n",
            "---  ------                    --------------  -----  \n",
            " 0   humidity_pct              2251 non-null   float64\n",
            " 1   lux_lx                    2251 non-null   float64\n",
            " 2   om_precipitation_mm       2251 non-null   float64\n",
            " 3   om_relative_humidity_pct  2251 non-null   float64\n",
            " 4   om_surface_pressure_pa    2251 non-null   float64\n",
            " 5   om_temperature_2m_c       2251 non-null   float64\n",
            " 6   om_wind_speed_10m_ms      2251 non-null   float64\n",
            " 7   pressure_pa               2251 non-null   float64\n",
            " 8   temperature_c             2251 non-null   float64\n",
            " 9   sine_hour                 2251 non-null   float64\n",
            " 10  cos_hour                  2251 non-null   float64\n",
            " 11  delta_temperature         2251 non-null   float64\n",
            " 12  temp_mean_6h              2251 non-null   float64\n",
            " 13  humidity_mean_6h          2251 non-null   float64\n",
            " 14  target_temperature_c      2251 non-null   float64\n",
            "dtypes: float64(15)\n",
            "memory usage: 345.9 KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1QAzy2vwUSf"
      },
      "outputs": [],
      "source": [
        "# Plotting\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# The last 5-day period\n",
        "ax = df[\"humidity_pct\"].plot(grid=True, marker='.', figsize=(8, 3.5))\n",
        "\n",
        "df[\"temperature_c\"].plot(\n",
        "    ax=ax, color='green', linewidth=2, label=\"Temperature (C)\"\n",
        ")\n",
        "\n",
        "# Add a legend to distinguish them\n",
        "ax.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HgbFZ8tXpt7W"
      },
      "outputs": [],
      "source": [
        "# The gaps indicate times the board was off"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tWHI4eK0p2en"
      },
      "outputs": [],
      "source": [
        "df = df.interpolate(method=\"linear\")\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "da7e0b1f"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "# Remove any remaining non-finite values before scaling to avoid NaNs in training weights\n",
        "numeric_cols = df.select_dtypes(include=\"number\").columns\n",
        "before_clean = len(df)\n",
        "df = df.loc[:, ~df.columns.duplicated()]\n",
        "df = df[np.isfinite(df[numeric_cols]).all(axis=1)]\n",
        "print(f\"Dropped {before_clean - len(df)} rows with non-finite values.\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zKDG259fpykR"
      },
      "outputs": [],
      "source": [
        "# The last 5-day period\n",
        "ax = df[\"humidity_pct\"].plot(grid=True, marker='.', figsize=(8, 3.5))\n",
        "\n",
        "df[\"temperature_c\"].plot(\n",
        "    ax=ax, color='green', linewidth=2, label=\"Temperature (C)\"\n",
        ")\n",
        "# Add a legend to distinguish them\n",
        "ax.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gO6DBJG0_tx_"
      },
      "source": [
        "# Feature Engineering\n",
        "We include the following features:\n",
        "1. `sine_hour` - This captures the cyclical nature of the hour of the day. e.g. when taking the sine of the hour of the day, 23:00 is closer to 00:00 as it should be.\n",
        "2. `cos_hour` - Similar to the above.\n",
        "3. `temperature_delta` -  The difference between the temperature at the current timestamp and the timestamp immediately before.\n",
        "4. `temp_mean_6h` - The average temperature over the past 6 hours at this current timestamp.\n",
        "5. `temp_humidity_6h` - The average humidity over the past 6 hours at this current timestamp."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6OumdXl1wmes"
      },
      "outputs": [],
      "source": [
        "hour_of_day = df.index.hour\n",
        "hour_of_day"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PY4KHDPPwDvd"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "df[\"sine_hour\"] = np.sin(2 * np.pi * hour_of_day / 24)\n",
        "df[\"cos_hour\"] = np.cos(2 * np.pi * hour_of_day / 24)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "swddXyqfxq5r"
      },
      "outputs": [],
      "source": [
        "df[\"delta_temperature\"] = df[\"temperature_c\"] - df[\"temperature_c\"].shift(1)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lPJvcMfJMvxG"
      },
      "outputs": [],
      "source": [
        "# Since the first row will be null, we fill it with the mean for this column\n",
        "df['delta_temperature'].fillna(df['delta_temperature'].mean(), inplace=True)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CseeoF-Nxqsz"
      },
      "outputs": [],
      "source": [
        "df[\"temp_mean_6h\"] = df[\"temperature_c\"].rolling(window=12, min_periods=1).mean()\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "378IIEsCyX7L"
      },
      "outputs": [],
      "source": [
        "df[\"humidity_mean_6h\"] = df[\"humidity_pct\"].rolling(window=12, min_periods=1).mean()\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qx03n-btwlm8"
      },
      "source": [
        "## Normalizing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qo7rmzPgGgWf"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "THYYsIHXw5kq"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Keep an unscaled copy of the temperature targets so outputs stay in Celsius\n",
        "# while inputs (including the observed temperature) are standardized\n",
        "target_col = 'target_temperature_c'\n",
        "df[target_col] = df['temperature_c']\n",
        "\n",
        "feature_cols = [col for col in df.select_dtypes(include='number').columns if col != target_col]\n",
        "feature_indices = [df.columns.get_loc(col) for col in feature_cols]\n",
        "target_index = df.columns.get_loc(target_col)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "df[feature_cols] = scaler.fit_transform(df[feature_cols])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dc900caa"
      },
      "source": [
        "\n",
        "**Note:** Unlike `microclimate_forecast_model.ipynb`, this notebook currently keeps the `temperature_c` column out of the `StandardScaler` so the network trains and predicts in real-world temperature units. In the microclimate notebook the line `combined_dataframe.drop(columns=target_column_names)` only removes the *future target* columns, so the current-temperature input *is* standardized along with the other features. If you want identical normalization here, create a separate unscaled copy of the target (e.g., `target_temperature_c`) and include `temperature_c` in the scaler's `feature_cols`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-SsPYSKSx7Z8"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LH-k7j2AEYmq"
      },
      "source": [
        "# Creating the Datasets used by the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G16KCm30GGrA"
      },
      "source": [
        "## Define Input Window Size and Prediction Window Size\n",
        "We want to use the previous 24 hours of data to predict the next 12 hours of temperatures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ifFIcd27Gd7b"
      },
      "outputs": [],
      "source": [
        "sample_size_in_hrs = 0.5 # we resampled to 30-min chunks\n",
        "window_size_in_hrs = 24\n",
        "\n",
        "# since each instance is a 30-min period, and we want a 24hr window\n",
        "seq_length = int(window_size_in_hrs / sample_size_in_hrs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62vISYVrEnwY"
      },
      "source": [
        "## Train, Test Split\n",
        "We use 80% of the data to train. Then the remaining 20% is then split into equal 10% segments. **No shuffling is done as the time series data needs to stay in chronological order**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_U4ydb5EXmb"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# First split: 80% and 20%\n",
        "df_train, df_temp = train_test_split(df, test_size=0.2,\n",
        "                                     random_state=42, shuffle=False)\n",
        "\n",
        "# Second split: split the remaining 20% into two 10% parts\n",
        "df_valid, df_test = train_test_split(df_temp, test_size=0.5,\n",
        "                                     random_state=42, shuffle=False)\n",
        "\n",
        "print(f\"Train: {len(df_train)}\")\n",
        "print(f\"Valid: {len(df_valid)}\")\n",
        "print(f\"Test: {len(df_test)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9lqiiIpMNGj"
      },
      "outputs": [],
      "source": [
        "df_train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0clKrRUbFqmK"
      },
      "outputs": [],
      "source": [
        "df_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kciEc__HK_i"
      },
      "source": [
        "## Converting DataFrames to Timeseries Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTPCKndbHato"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhLhEV12FtXU"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def split_inputs_and_targets(\n",
        "    multivariable_series,\n",
        "    ahead: int = 24,   # next 24 half-hour slots\n",
        "):\n",
        "    # Split into input window and target horizon\n",
        "    input_sequence = multivariable_series[:, :-ahead, :]\n",
        "    # Use tf.gather to select columns using feature_indices\n",
        "    inputs = tf.gather(input_sequence, tf.constant(feature_indices), axis=-1) # shape: (batch, seq_length, num_features)\n",
        "    targets = multivariable_series[:, -ahead:, target_index]   # shape: (batch, ahead)\n",
        "\n",
        "    # Tell TensorFlow the exact shapes so RNN can unroll\n",
        "    # batch dimension stays None, time dimension is fixed\n",
        "    inputs.set_shape((None, seq_length, len(feature_cols)))\n",
        "    targets.set_shape((None, ahead))\n",
        "\n",
        "    return inputs, targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCKWU43wHI5Q"
      },
      "outputs": [],
      "source": [
        "train_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
        "    df_train.to_numpy(),\n",
        "    targets=None,\n",
        "    sequence_length=seq_length + 24,\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ").map(split_inputs_and_targets)\n",
        "\n",
        "train_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKHNylEYHeZ-"
      },
      "outputs": [],
      "source": [
        "valid_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
        "    df_valid.to_numpy(),\n",
        "    targets=None,\n",
        "    sequence_length=seq_length + 24,\n",
        "    batch_size=32\n",
        ").map(split_inputs_and_targets)\n",
        "valid_ds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnpLgOfeHxcj"
      },
      "source": [
        "# Build and Compile the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqUUv3QlIpX7"
      },
      "source": [
        "## I Should Use Keras Tuner here once i get the base model to run"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sKKqPFqJFnv"
      },
      "source": [
        "## Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWsUj0bWHwWi"
      },
      "outputs": [],
      "source": [
        "num_features = len(feature_cols)\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(seq_length, num_features)),\n",
        "    tf.keras.layers.SimpleRNN(64, return_sequences=True,unroll=True),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.SimpleRNN(64,unroll=True),\n",
        "    tf.keras.layers.Dense(64, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(24)\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgGK7BqQIcko"
      },
      "outputs": [],
      "source": [
        "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_mae\",\n",
        "    patience=15,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOOzBDv-I1JH"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    loss=tf.keras.losses.Huber(),\n",
        "    optimizer=optimizer,\n",
        "    metrics=[\"mae\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2B6D05lnJQPo"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTTodCG9I6cy"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    train_ds, validation_data=valid_ds,\n",
        "    epochs=500, callbacks=[early_stopping_cb]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gSFLhiEn_bCH"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    train_ds, validation_data=valid_ds,\n",
        "    epochs=500, callbacks=[early_stopping_cb]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9292cc80"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "# Ensure the trained model has only finite weights before exporting to TFLite/X-CUBE-AI\n",
        "for idx, weight in enumerate(model.get_weights()):\n",
        "    if not np.all(np.isfinite(weight)):\n",
        "        raise ValueError(f\"Non-finite values found in weight tensor {idx}; check preprocessing and training stability before export.\")\n",
        "print(\"Model weights verified as finite.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JZEjQ0KJUlf"
      },
      "source": [
        "# Using the Model to Make Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-7TpuZmJXzm"
      },
      "outputs": [],
      "source": [
        "def predict_12_hours(model, input_df, seq_length, start_idx, target_col_name,\n",
        "                     window_size_in_hrs):\n",
        "  X = input_df[feature_cols].to_numpy()[np.newaxis, start_idx:start_idx+seq_length]\n",
        "  print(f\"Shape of Input Data: {X.shape}\")\n",
        "\n",
        "  Y_pred = model.predict(X)[0]\n",
        "  print(f\"Model Prediction: {Y_pred}\")\n",
        "\n",
        "  actual_next_12_hrs = input_df[start_idx+seq_length:\n",
        "                                start_idx+seq_length+window_size_in_hrs][target_col_name].to_numpy()\n",
        "  print(f\"Actual Next 12 Hours: {actual_next_12_hrs}\")\n",
        "\n",
        "  for i in range(window_size_in_hrs):\n",
        "    model_pred_in_deg = Y_pred[i]\n",
        "    actual_in_deg = actual_next_12_hrs[i]\n",
        "    pred_error = model_pred_in_deg - actual_in_deg\n",
        "\n",
        "    print(f\"{(i+1) * 30} MINUTES INTO THE FUTURE!\")\n",
        "    print(f\"Model Prediction: {model_pred_in_deg} degrees celcius.\")\n",
        "    print(f\"Actual Value: {actual_in_deg} degrees celcius.\")\n",
        "    print(f\"Prediction Error: {pred_error} degrees celcius.\")\n",
        "    print('*'*20)\n",
        "\n",
        "  return Y_pred, actual_next_12_hrs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2YBtU0irNMdf"
      },
      "outputs": [],
      "source": [
        "Y_pred_deg, actual_val_deg = predict_12_hours(\n",
        "    model, df_valid, seq_length, 0, target_col,\n",
        "    window_size_in_hrs\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q39uQIbNN6bZ"
      },
      "source": [
        "# Evaluating the model on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKBVFnB1OH33"
      },
      "outputs": [],
      "source": [
        "df_test.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9V4k9aANfC2"
      },
      "outputs": [],
      "source": [
        "test_ds = tf.keras.utils.timeseries_dataset_from_array(\n",
        "    df_test.to_numpy(),\n",
        "    targets=None,\n",
        "    sequence_length=seq_length + 24,  # same as in training\n",
        "    batch_size=32\n",
        ").map(split_inputs_and_targets)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OOPStrWOER3"
      },
      "outputs": [],
      "source": [
        "results = model.evaluate(test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1rW6XGOOF0w"
      },
      "outputs": [],
      "source": [
        "test_mae = results[1]\n",
        "test_mae"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBu-C3pvOvS6"
      },
      "outputs": [],
      "source": [
        "test_mae_deg = test_mae\n",
        "print(f\"Test MAE Degrees Celcius: {test_mae_deg}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6sRJux3QcH4"
      },
      "source": [
        "# Preparing the Model for Deployment on the Embedded Board"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00c60654"
      },
      "source": [
        "## Structured pruning and footprint analysis\n",
        "We apply a manual, structured pruning pass to the RNN (removing the weakest neurons per layer) and log the footprint at each stage (full, pruned, and quantized).\n",
        "Pinned NumPy wheels remain to avoid ABI conflicts seen on Colab.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5278a22e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tempfile\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\n",
        "\n",
        "\n",
        "def calculate_macs(model):\n",
        "    sample_spec = tf.TensorSpec([1, seq_length, num_features], tf.float32)\n",
        "    concrete_func = tf.function(model).get_concrete_function(sample_spec)\n",
        "    frozen_func = convert_variables_to_constants_v2(concrete_func)\n",
        "    graph_def = frozen_func.graph.as_graph_def()\n",
        "\n",
        "    with tf.Graph().as_default() as graph:\n",
        "        tf.graph_util.import_graph_def(graph_def, name='')\n",
        "        run_meta = tf.compat.v1.RunMetadata()\n",
        "        opts = tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()\n",
        "        flops = tf.compat.v1.profiler.profile(graph=graph, run_meta=run_meta, cmd='op', options=opts)\n",
        "\n",
        "    macs = flops.total_float_ops // 2 if flops is not None else None\n",
        "    return macs\n",
        "\n",
        "\n",
        "def get_model_size_kb(model):\n",
        "    fd, temp_path = tempfile.mkstemp(suffix='.h5')\n",
        "    os.close(fd)\n",
        "    model.save(temp_path, include_optimizer=False)\n",
        "    size_kb = os.path.getsize(temp_path) / 1024\n",
        "    os.remove(temp_path)\n",
        "    return size_kb\n",
        "\n",
        "\n",
        "def summarize_keras_model(label, model):\n",
        "    macs = calculate_macs(model)\n",
        "    macs_display = f\"{macs:,}\" if macs is not None else 'N/A'\n",
        "    params = model.count_params()\n",
        "    size_kb = get_model_size_kb(model)\n",
        "    print(f\"\"\"{label}:\n",
        " - Parameters: {params:,}\n",
        " - MACs (approx): {macs_display}\n",
        " - Size: {size_kb:.2f} KB\n",
        "\"\"\")\n",
        "\n",
        "\n",
        "def summarize_tflite_model(label, tflite_bytes, reference_keras_model=None):\n",
        "    params = reference_keras_model.count_params() if reference_keras_model else 'N/A'\n",
        "    macs = calculate_macs(reference_keras_model) if reference_keras_model else None\n",
        "    macs_display = f\"{macs:,}\" if macs is not None else 'N/A'\n",
        "    size_kb = len(tflite_bytes) / 1024\n",
        "    print(f\"\"\"{label}:\n",
        " - Parameters: {params:,}\n",
        " - MACs (approx): {macs_display}\n",
        " - Size: {size_kb:.2f} KB\n",
        "\"\"\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7a9c729"
      },
      "outputs": [],
      "source": [
        "# Baseline footprint before pruning\n",
        "summarize_keras_model(\"Full Keras model\", model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yIDEK4w3Jsl"
      },
      "outputs": [],
      "execution_count": null,
      "source": [
        "pruned_model, pruning_masks = structured_prune_model(model, target_sparsity=0.5)\n",
        "\n",
        "# Use a fresh optimizer so it can track the cloned model's variables.\n",
        "# Reusing the previously built optimizer causes KeyErrors when it sees\n",
        "# variables (e.g., the SimpleRNN kernel) that were not part of the original\n",
        "# optimizer state.\n",
        "pruning_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "pruning_optimizer.build(pruned_model.trainable_variables)\n",
        "\n",
        "pruned_model.compile(\n",
        "    loss=tf.keras.losses.Huber(),\n",
        "    optimizer=pruning_optimizer,\n",
        "    metrics=['mae']\n",
        ")\n",
        "\n",
        "pruning_callbacks = [\n",
        "    StructuredPruningCallback(pruning_masks),\n",
        "    early_stopping_cb,\n",
        "]\n",
        "\n",
        "pruned_history = pruned_model.fit(\n",
        "    train_ds,\n",
        "    validation_data=valid_ds,\n",
        "    epochs=10,\n",
        "    callbacks=pruning_callbacks,\n",
        ")\n",
        "\n",
        "summarize_keras_model(\"Structured pruned model\", pruned_model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sr8J7MhRDAV"
      },
      "source": [
        "## Quantizing, Pruning and Saving the TFLite Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tE5OraZfPaXF"
      },
      "outputs": [],
      "source": [
        "def representative_dataset():\n",
        "    for batch in tf.keras.utils.timeseries_dataset_from_array(\n",
        "        data=df_train[feature_cols].to_numpy().astype(np.float32),\n",
        "        targets=None,\n",
        "        sequence_length=seq_length,\n",
        "        batch_size=1,\n",
        "    ).take(200):\n",
        "        yield [batch]\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(pruned_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_dataset\n",
        "converter.target_spec.supported_ops = [\n",
        "    tf.lite.OpsSet.TFLITE_BUILTINS_INT8\n",
        "]\n",
        "# Disable lowering of tensor list ops to avoid TF Lite conversion failures for RNN layers.\n",
        "# converter._experimental_lower_tensor_list_ops = False\n",
        "\n",
        "# Keep strict int8 inputs/outputs for fully quantized inference.\n",
        "converter.inference_input_type = tf.int8\n",
        "converter.inference_output_type = tf.int8\n",
        "\n",
        "quantized_model = converter.convert()\n",
        "with open(\"quantized_rnn_model.tflite\", \"wb\") as f:\n",
        "    f.write(quantized_model)\n",
        "\n",
        "\n",
        "summarize_tflite_model(\"Quantized int8 model\", quantized_model, reference_keras_model=pruned_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qoSB9DDRRNV"
      },
      "source": [
        "## Reload the TFLite Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gROB29RfRHwX"
      },
      "outputs": [],
      "source": [
        "# Load the TFLite model\n",
        "interpreter = tf.lite.Interpreter(model_path=\"quantized_rnn_model.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output details (optional)\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "print(\"Model loaded successfully!\")\n",
        "print(\"Input details:\", input_details)\n",
        "print(\"Output details:\", output_details)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kFFGZ8ARYdK"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Evaluating the size of the tflite model\n",
        "import os\n",
        "\n",
        "file_path = \"quantized_rnn_model.tflite\"\n",
        "size_in_bytes = os.path.getsize(file_path)\n",
        "size_in_kb = size_in_bytes / 1024\n",
        "size_in_mb = size_in_kb / 1024\n",
        "\n",
        "print(f\"Model size: {size_in_bytes} bytes ({size_in_kb:.2f} KB / {size_in_mb:.2f} MB)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNyStttHRqwt"
      },
      "source": [
        "## Using the TFLite Model to Make a Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4qR_qeUXRfLH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Prepare input (same as Keras)\n",
        "input_scale, input_zero_point = input_details[0][\"quantization\"]\n",
        "output_scale, output_zero_point = output_details[0][\"quantization\"]\n",
        "\n",
        "def quantize_input(window: np.ndarray) -> np.ndarray:\n",
        "    return np.clip(np.round(window / input_scale + input_zero_point), -128, 127).astype(np.int8)\n",
        "\n",
        "def dequantize_output(tensor: np.ndarray) -> np.ndarray:\n",
        "    return (tensor.astype(np.float32) - output_zero_point) * output_scale\n",
        "\n",
        "X = df_valid[feature_cols].to_numpy()[np.newaxis, :seq_length].astype(np.float32)  # shape: (1, seq_length, features)\n",
        "X_int8 = quantize_input(X) # Quantize input\n",
        "\n",
        "# Set input tensor\n",
        "interpreter.set_tensor(input_details[0][\"index\"], X_int8) # Pass quantized int8 input\n",
        "\n",
        "# Run inference\n",
        "interpreter.invoke()\n",
        "\n",
        "# Get prediction\n",
        "output_data_int8 = interpreter.get_tensor(output_details[0][\"index\"])\n",
        "output_data = dequantize_output(output_data_int8) # Dequantize output\n",
        "print(\"Prediction:\", output_data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHnM4U0GSHcM"
      },
      "source": [
        "## Evaluating the TFLite Model on the Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bgj3rWTMR5Wj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Get input and output details\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "# Get quantization parameters from the loaded model details\n",
        "input_scale, input_zero_point = input_details[0][\"quantization\"]\n",
        "output_scale, output_zero_point = output_details[0][\"quantization\"]\n",
        "\n",
        "def quantize_input(window: np.ndarray) -> np.ndarray:\n",
        "    return np.clip(np.round(window / input_scale + input_zero_point), -128, 127).astype(np.int8)\n",
        "\n",
        "def dequantize_output(tensor: np.ndarray) -> np.ndarray:\n",
        "    return (tensor.astype(np.float32) - output_zero_point) * output_scale\n",
        "\n",
        "seq_length = 48  # or whatever your window size is\n",
        "num_features = len(feature_cols)\n",
        "\n",
        "# Store predictions and true values\n",
        "preds = []\n",
        "trues = []\n",
        "\n",
        "for start in range(len(df_test) - seq_length - 24 + 1):  # 24 is your prediction horizon\n",
        "    X = df_test[feature_cols].to_numpy()[start:start+seq_length].astype(np.float32)\n",
        "    X_int8 = quantize_input(X[np.newaxis, ...])  # Quantize input\n",
        "\n",
        "    interpreter.set_tensor(input_details[0]['index'], X_int8) # Pass quantized int8 input\n",
        "    interpreter.invoke()\n",
        "\n",
        "    output_data_int8 = interpreter.get_tensor(output_details[0]['index'])\n",
        "    y_pred = dequantize_output(output_data_int8)[0] # Dequantize output\n",
        "    preds.append(y_pred)\n",
        "\n",
        "    # True values for the next 24 steps of the target column (e.g., temperature)\n",
        "    y_true = df_test.iloc[start+seq_length:start+seq_length+24][target_col].to_numpy()\n",
        "    trues.append(y_true)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZ3W7RekSu2I"
      },
      "outputs": [],
      "source": [
        "preds = np.array(preds)\n",
        "trues = np.array(trues)\n",
        "\n",
        "# Temperature targets are kept in their original scale, so predictions are already in Celsius\n",
        "mae = np.mean(np.abs(preds - trues))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mshVIq58Sy-o"
      },
      "outputs": [],
      "source": [
        "print(f\"TFLite Model Test MAE: {mae}\")\n",
        "print(f\"TFLite Model Test MAE Degrees Celcius: {mae}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}